---
title: "Missing Data and Imputation"
author: "Tharun Teja Gandham & Mourya Rai Papolu (Advisor: Dr. Cohen)"
date: '`r Sys.Date()`'
format:
  html:
    code-fold: true
course: Capstone Projects in Data Science
bibliography: references.bib # file contains bibtex for references
#always_allow_html: true # this allows to get PDF with HTML features
self-contained: true
execute: 
  warning: false
  message: false
editor: 
  markdown: 
    wrap: 72
header-includes:
  - |
    <style>
      body {
        background: linear-gradient(to right, #7db5e3, #d3d3d3); /* Change this color as needed */
      }
    </style>
---


## Introduction

Across healthcare, social sciences and finance sectors missing data continues as an extensive problem because it creates biased outcomes and reduces research reliability and weakens research conclusions unless appropriate data handling methods are used [@salgado2016missing]. The Electronic Health Records (EHR) dataset faces high vulnerability to missing data from technological breakdowns as well as human mistakes and data loss incidents. In various fields missing data originates from survey non-responses and equipment failures as well as data entry errors [@alwateer2024missing]. Improper handling of missing data leads to severe consequences on the quality of research findings and decision-making processes particularly when analyzing clinical epidemiology and structured datasets. 

The solution for this issue requires researchers to implement imputation techniques that provide estimated values for missing data points. Various imputation methods exist which include basic methods like mean substitution and advanced techniques using multiple imputation along with machine learning models. The selection of a method for imputation requires knowledge of the missing data pattern because it can be MCAR or MAR or MNAR. Mean imputation and listwise deletion remain straightforward to use yet they produce biases or overlook missing value uncertainty [@pedersen2017missing].Multiple imputation and K-Nearest Neighbors (KNN) and Random Forests machine learning models effectively manage complex datasets that have high missingness levels and non-linear relationships. Proper evaluation procedures must be conducted because these techniques need to balance both computational efficiency and accuracy levels.

The selection of imputation methods relies on both the dataset characteristics and the nature of missing data according to recent research findings. Research on 58 articles demonstrates traditional methods work best for data sets with straightforward missingness patterns but deep learning and hybrid models deliver superior results for complex data patterns. The social science field demonstrates that semi-parametric techniques including predictive mean matching with hot deck imputation deliver superior results compared to fully parametric methods for item-nonresponse data according to [@durrant2005imputation]. The research emphasizes the requirement for imputation approaches which match the unique needs of datasets along with their associated research goals.

The analysis evaluates five imputation approaches based on mean, mode, regression, K-Nearest Neighbors (KNN), and Multiple Imputation by Chained Equations (MICE) through application on the well-known Titanic dataset. The research objective is to determine which of these five methods produces the best results for handling missing data in structured datasets so researchers can guarantee data reliability and improve their research findings' validity. The research findings from this analysis will expand existing knowledge about imputation methods and supply actionable tips to scientists and practitioners who need to handle missing data.


### Literature Review

Missing data is common problem in data science, which affects the accuracy and reliability of analyses across different domains. This section summarizes major findings from existing research on ‘missing data imputation’, which focus on old traditional and new advanced methods and their applications, limitations.

1. Mechanisms of Missing Data:

How missing data is dealt with in practice depends entirely on what type of missingness it has, so that it can be classified as Missing Completely at Random (MCAR), Missing at Random (MAR), or Not Missing at Random (NMAR). In terms of clinical research, MAR is a very common means of missing data, often being the result of careening into trees or equipment breaking [@salgado2016missing]. Identifying these mechanisms is important for correctly chosen allocation mechanisms. [@lee2024prevention] stress that robustness across time for data acquisition must be used to prevent missing data in clinical studies together with monitoring as close to real-time as possible.

2. Traditional Imputation Methods:

Traditional methods such as mean substitution, regression imputation, and listwise deletion are simple, widely used, but also introduce bias or reduce statistical power. When mean substitution is performed, the original distribution of data is disrupted as one point is substituting every missing figure. It may be biased or not exceed thoroughness in cases where people can participate for complete information and which doesn't require objectives. Sample size is reduced by listwise deletion hence leading to loss of statistical power [@alwateer2024missing]. However, traditional methods still remain popular because of their simplicity of implementation and the manner in which they focus on bias rather than noise in data. [@yadav2024computational] offer a comprehensive overview of these methods, pointing out that their main employment is low-dimensional data sets with simple missing patterns

3. Advanced Imputation Techniques:

Multiple imputation alongside machine learning and deep learning models demonstrate effectiveness when dealing with complex datasets having substantial amounts of missing data. Referred to by Little & Rubin [@yadav2024computational] Multiple Imputation by Chained Equations (MICE) produces numerous datasets with imputed values which it then combines to deal with uncertainty in clinical research. The algorithm MissForest uses Random Forests to analyze mixed-type data while showing reliable results across MCAR, MAR, and MNAR data conditions according to [@stekhoven2012missforest]. The application of K-Nearest Neighbors (KNN) and Random Forests along with Autoencoders in machine learning demonstrates exceptional ability to analyze high-dimensional data structures with non-linear relationships according to [@karim2024imputation] thoroughly examines state-of-the-art methods which show excellent performance in processing complex multi-dimensional data (2024).

4. Applications and Challenges:

With structured data sets suffering from missingness and such errors, method of imputation has a big effect on the quality of the analysis. While imputing traditionaly works fine for data with simple missingness patterns, a systematic review of 58 articles shows that in more complex casus only advanced technologies such as deep learning are better able to handle this issue out [@afkanpour2024identify]. But challenges remain, including the computational workload and lack of widely accepted methods for assessing results, which act as barriers to employing these new standards [@alwateer2024missing]. Discussing the potential and pitfalls of m method of imputation for datasets their epidemiological research is based on [@sterne2009multiple] particularly emphasize model specification and the need for sensictivity analysis to see if results are being biased in any one direction.

5. Semi-Parametric and Hybrid Approaches:

The hybrid approach is increasingly and becoming popular with researchers Just see the number of references to it on Google Scholar this year
Outperforming fully parametric approaches in social science research, semi-parametric methods such as predictive mean matching and hot deck imputation show great potential for item-nonresponse data [@durrant2005imputation].
Hybrid methods, combining traditional methods and machine learning, also deliver satisfactory results in increasing imputation accuracies without increasing computational time at all [@afkanpour2024identify].It is noted by [@lee2024prevention] that in clinical research settings, hybrid ones may well operate. Whether because a better preventive device with more sophisticated analytics yields even worse data quality than ever before; or due to some other double-combining of tools and methods, weightless chances must not be missed out on because of their particular novelty [@farhangfar2007novel]. 


*This is my work and I want to add more work...*

## Methods

#### 1.Mean and Mode Imputation

Mean and mode imputation are simple methods that replace missing values with the average (for numerical data) or most common value (for categorical data) of the observed values.

Imputation with mean involves substituting missing values with the arithmetic mean calculated from observed values.

This method replaces missing values by using the mode which represents the most frequent value present in observed data points.

The implementation of these methods remains straightforward yet data distortion may occur when missing values exceed a certain threshold [@pedersen2017missing] [@afkanpour2024identify].

The mean imputation formula is:

$$
\hat{x}_i = \bar{x} = \frac{1}{n} \sum_{j=1}^{n} x_j
$$
	
where x^i is the imputed value, xˉ is the mean of the observed values, n is the number of observed values, and xj is the j-th observed value [@pedersen2017missing] [@afkanpour2024identify].

 Mode Imputation:
$$
\hat{x}_i=mode(x)
$$
where mode(x)mode(x) is the most frequently occurring value in the dataset [@pedersen2017missing] [@afkanpour2024identify].

	

#### 2.Regression Imputation
A regression model enables regression imputation to predict missing values by analyzing the connections between other variables in the dataset. For example:

The Age column's missing values can be predicted with the help of Pclass and Fare variables.

The method requires linear variable relationships as its foundation but provides advanced handling compared to mean/mode imputation (Little & Rubin, 2002; [@farhangfar2007novel].

Regression Model:
The regression imputation formula is:

$$
\begin{align}
\hat{x}_i &= \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \dots + \beta_p x_p + \epsilon_i \\
\text{where} \quad \beta_0 &= \text{intercept}, \quad \beta_1, \dots, \beta_p = \text{coefficients}
\end{align}
$$
where x^i is the predicted value, β0,β1,…,βp are the regression coefficients, and ϵi is the error term [@yadav2024computational]; [@little2019statistical].

#### 3.K-Nearest Neighbors (KNN) Imputation
   K-Nearest Neighbors (KNN) is a machine learning algorithm used for both classification and regression tasks. In the context of missing data imputation:

KNN finds the K most similar rows (neighbors) in the dataset based on the values of other features.

It then uses the values from these neighbors to estimate the missing values.
For each row with a missing value, KNN looks at the other features (columns) in the dataset.It calculates the distance (e.g., Euclidean distance) between the row with the missing value and all other rows.

It selects the K nearest neighbors (rows) that are most similar based on the distance.

The algorithm obtains the average measurement point for numerical data and most frequent value for categorical data from the k nearest neighbors.

The impute.knn() function from the impute package in R enables users to execute KNN imputation. KNN proves useful when data points that are similar in nature tend to possess similar values [@alwateer2024missing]; .

KNN Formula:
The KNN imputation formula is:

$$
\hat{x}_i = \frac{1}{k} \sum_{j \in N_k(i)} x_j \label{eq:knn} 
$$
k  Specifies the number of nearest neighbors to use.

As shown in Equation , KNN imputation replaces missing values with the average of the nearest neighbors.
where x^i is the imputed value, Nk(i) is the set of k nearest neighbors, and xj is the value of the j-th neighbor [@alwateer2024missing] [@stekhoven2012missforest].

#### 4.Multiple Imputation by Chained Equations (MICE)
MICE serves as a popular method for missing data management through its creation of numerous complete versions of original datasets. MICE proves effective in dealing with complex missing data patterns provided data follow the MAR assumption. The following description of MICE features a detailed analysis supported by references from Pedersen et al. (2017). 

How MICE Works

- Initialization:

MICE starts by filling in the missing values with initial guesses (e.g., mean, median, or random values). These are temporary placeholders and will be refined in subsequent steps (Pedersen et al., 2017).

- Iterative Imputation:

Each variable with missing data within MICE undergoes regression model analysis to generate predicted values by using other dataset variables. A model selection depends on the variable type for regression analysis.
Linear regression for numeric variables.
Logistic regression for binary categorical variables.
Multinomial regression for multi-class categorical variables (Pedersen et al., 2017).
The imputation process runs repeatedly while updating missing value predictions during each cycle until prediction changes reach an unnoticeable point.

- Multiple Imputed Datasets:

The MICE method creates five to ten datasets which represent diverse plausible alternatives for missing data values. The method represents the unknown nature of missing data values (Pedersen et al., 2017).

- Combining Results:

Each data set created through MICE receives separate analysis for the study interest such as logistic regression. Combines the results from these datasets to provide unbiased and valid estimates of associations according to Pedersen et al. (2017).

- For now we are proceeding with mean/mode , regression and knn imputations.

## Data Exploration and Visualization

-   Describe your data sources and collection process.

    (https://www.kaggle.com/c/titanic/data)
    
  The Titanic dataset from Kaggle is a widely used dataset for data analysis and machine learning projects. It contains information about the passengers aboard the Titanic, including whether they survived or not. The dataset includes features such as:
      
- PassengerId: A unique identifier for each passenger.
-	Survived: Whether the passenger survived (1) or not (0).
-	Pclass: The ticket class (1st, 2nd, or 3rd), which is a proxy for socio-economic status.
-	Name: The name of the passenger.
-	Sex: The gender of the passenger (male or female).
-	Age: The age of the passenger.
-	SibSp: The number of siblings/spouses aboard the Titanic.
-	Parch: The number of parents/children aboard the Titanic.
-	Ticket: The ticket number.
-	Fare: The fare paid for the ticket.
-	Cabin: The cabin number (many missing values).
-	Embarked: The port of embarkation (C = Cherbourg, Q = Queenstown, S = Southampton).


```{r}
# Set CRAN mirror
options(repos = c(CRAN = "https://cloud.r-project.org"))

# Install and load ggplot2
if (!require(ggplot2)) install.packages("ggplot2")
library(ggplot2)

# Install and load naniar
if (!require(naniar)) install.packages("naniar")
library(naniar)


```


```{r}
library(dplyr)
#titanic dataset
train<-read.csv("train.csv")
# Replace empty strings with NA in specific columns
train <- train %>%
  mutate(
    Cabin = na_if(Cabin, ""),
    Embarked = na_if(Embarked, "")
  )
summary(train)
```
```{r}
#missing values column wise
colSums(is.na(train))
```

- Age column has 177 missing values 
- Cabin column has large number of missing values 687
- Similarly embarked column has 2 missing values.

##### Unexpected patterns or anomalies.

```{r}
# creating a data frame to show the missing values percentage
missing_data<-data.frame(
  column_name=names(train),
  missing_val=colSums(is.na(train)),
  missing_percent=colSums(is.na(train)/nrow(train))*100
)

print(missing_data)

```
The Titanic dataset has missing values primarily in the Age and Cabin columns, with 177 (19.87%) and 687 (77.10%) missing entries, respectively. The Embarked column has only 2 (0.22%) missing values, which is negligible. All other columns, such as PassengerId, Survived, and Sex, are complete with no missing data, making them reliable for analysis.


```{r}

#visualization of my data set through ggplot
ggplot(missing_data,aes(x=column_name,y=missing_val))+
  geom_bar(stat="identity",fill="blue")+
  labs(title="missing values in titanic data set", x="column_names", y="number of missing values")+
  theme_bw()

```
- each column and their missingness compared in bar chart, cabin column has highest number of missing values.

```{r}

vis_miss(train)+
  labs(title="missingness pattern in dataset")
```


```{r}
#Whether the passenger survived (1) or not (0)
ggplot(train, aes(x = factor(Survived))) +  
  geom_bar(fill = "steelblue") +  
  labs(title = "Survival Count", x = "Survived", y = "Count")  
```


The plot shows that fewer passengers survived . This depiction emphasizes the survival rate imbalance in the data since it strongly affects both analytical processes and model predictions of survival estimates.

```{r}
ggplot(train, aes(x = Sex, fill = factor(Survived))) +
  geom_bar(position = "fill") +
  labs(title = "Survival Rate by Gender", x = "Gender", y = "Proportion", fill = "Survived")
```

- we can say that more female passengers are survived than male passengers.

```{r}
ggplot(train, aes(x = factor(Pclass), fill = factor(Survived))) +
  geom_bar(position = "fill") +
  labs(title = "Survival Rate by Passenger Class", x = "Class", y = "Proportion", fill = "Survived")
```

```{r}
ggplot(train, aes(x = factor(Survived), y = Age, fill = factor(Survived))) +
  geom_boxplot() +
  labs(title = "Age Distribution by Survival", x = "Survived", y = "Age", fill = "Survived")
```

- We can see that most survivors are in the 20–40 age range, so missing ages for survivors might be imputed with a value in that range.
- Median Age: The median age of survivors (blue box) is slightly higher than that of non-survivors (red box).
- Age Spread: Both groups have a similar spread of ages, meaning age alone may not be a strong factor in survival.



```{r}
# Age Distribution  
ggplot(train, aes(x = Age)) +  
  geom_histogram(binwidth = 5, fill = "gray", color = "black") +  
  labs(title = "Age Distribution", x = "Age", y = "Count")  

```

The histogram displays the distribution of passenger ages. The majority of passengers fall within the 20–40 age range, with a peak around the early twenties. A smaller number of passengers are younger children or older adults, with very few above 60. The distribution is right-skewed, indicating more younger passengers compared to older ones. This visualization helps understand the overall age demographics and can guide imputation strategies for missing age values.


```{r}
library(reshape2)

# Select numeric columns
numeric_data <- train %>%
  select(Age, Fare, SibSp, Parch, Survived)

# Compute correlation matrix
cor_matrix <- cor(numeric_data, use = "complete.obs")

# Melt the correlation matrix for ggplot
melted_cor_matrix <- melt(cor_matrix)

# Plot heatmap
ggplot(melted_cor_matrix, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", midpoint = 0) +
  labs(title = "Correlation Heatmap", x = "", y = "", fill = "Correlation") +
  theme_bw()
```

This correlation heatmap provides insights into relationships between key numerical variables in our dataset. Darker red indicates a strong positive correlation, while purple represents a negative correlation. For example, 'Fare' and 'Survived' show a positive correlation, suggesting passengers who paid higher fares had a higher survival rate. Identifying these relationships helps in understanding data patterns, which is crucial when handling missing values, as correlations can guide imputation strategies.

## Analysis and Results

#### Mean and Mode Imputation

```{r}
# copy of the original data set
train_imputed1<- train
```

```{r}
# Mean imputation for Age( numeric column)
mean_age <- mean(train_imputed1$Age, na.rm = TRUE) #(remove na while caluclating mean)
train_imputed1 <- train_imputed1 %>%
  mutate(Age = ifelse(is.na(Age), mean_age, Age))

```

```{r}
# Mode imputation replaces missing values in categorical columns (e.g., Embarked) with the mode (most frequent value) of the column.

# Mode imputation for Embarked
mode_embarked <- names(sort(table(train_imputed1$Embarked), decreasing = TRUE))[1]
train_imputed1 <- train_imputed1 %>%
  mutate(Embarked = ifelse(is.na(Embarked), mode_embarked, Embarked))

# Mode imputation for Cabin
mode_cabin <- names(sort(table(train_imputed1$Cabin), decreasing = TRUE))[1]
train_imputed1 <- train_imputed1 %>%
  mutate(Cabin = ifelse(is.na(Cabin), mode_cabin, Cabin))


colSums(is.na(train_imputed1))
```
```{r}
#  Visualizing Age distribution after imputation
ggplot(train_imputed1, aes(x = Age)) +
  geom_histogram(binwidth = 5, fill = "gray", color = "black") +
  labs(title = "Age Distribution After Mean Imputation", x = "Age", y = "Count")
```
```{r}
ggplot(train_imputed1, aes(x = factor(Survived), y = Age, fill = factor(Survived))) +
  geom_boxplot() +
  labs(title = "Age Distribution by Survival", x = "Survived", y = "Age", fill = "Survived")
```

##### REGRESSION IMPUTATION
```{r}
#linear regression for age (numerical data)
train_regression<-train
# Fit the linear regression model
age_model <- lm(Age ~ Pclass + Sex + SibSp + Parch + Fare, data = train_regression)

# Identify rows with missing Age
missing_age <- is.na(train_regression$Age)

# Predict missing Age values
train_regression$Age[missing_age] <- predict(age_model, newdata = train_regression[missing_age, ])

```

```{r}

sum(is.na(train_regression$Embarked))
```

Since Embarked column has 3 categories: "C", "Q", "S" we are using Multinomial Logistic Regression for Embarked.
```{r}
library(nnet)

# Fit a multinomial logistic regression model for Embarked
embarked_model <- multinom(Embarked ~ Pclass + Sex + Age + SibSp + Parch + Fare, 
                           data = train_regression)
missing_embarked <- is.na(train_regression$Embarked)

predicted_embarked <- predict(embarked_model, newdata = train_regression[missing_embarked, ], type = "class")

# Replace missing values with predicted values
train_regression$Embarked[missing_embarked] <- predicted_embarked

```

- Too Many Missing Values: 687 missing values out of 891 is a lot, and regression imputation might not work well due to the lack of sufficient data.
- The Cabin column has many unique categories (e.g., "G6", "C103", "C123", etc.), making regression imputation computationally expensive and less reliable.
- So i am using mode imputation for this column.
```{r}
# Mode imputation for Cabin
mode_reg <- names(sort(table(train_regression$Cabin), decreasing = TRUE))[1]
train_regression <- train_regression %>%
  mutate(Cabin = ifelse(is.na(Cabin), mode_reg, Cabin))


colSums(is.na(train_regression))
```
using regression imputation techiniques i Replaced NA values .

##### KNN IMPUTATION

```{r}

# Load the VIM package
library(VIM)

# Perform KNN imputation
train_knn <- kNN(train, k = 5)


# Check missing values after imputation
colSums(is.na(train_knn))
```


### Modeling and Results
####Comparing Age distributions

```{r}

library(ggplot2)


ggplot(train, aes(Age)) + 
  geom_histogram(fill="red", alpha=0.5, bins=30) + 
  ggtitle("Original Age Distribution") +
  theme_minimal()

ggplot(train_imputed1, aes(Age)) + 
  geom_histogram(fill="blue", alpha=0.5, bins=30) + 
  ggtitle("Age Distribution after Mean Imputation") +
  theme_minimal()

ggplot(train_regression, aes(Age)) + 
  geom_histogram(fill="green", alpha=0.5, bins=30) + 
  ggtitle("Age Distribution after Regression Imputation") +
  theme_minimal()

ggplot(train_knn,aes(Age)) +
  geom_histogram(fill="gold",alpha=0.5, bins=30)+
  ggtitle("Age Distribution after knn Imputation") +
  theme_minimal()
```
#### Model Performance
```{r}

model_1 <- Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked

# Train models on different imputed datasets
logit_mean <- glm(model_1, data = train_imputed1, family = "binomial")
logit_reg <- glm(model_1, data = train_regression, family = "binomial")
logit_knn <- glm(model_1, data = train_knn, family = "binomial")

```

```{r}
install.packages("caret", dependencies = TRUE)
library(caret)

```
```{r}
# Convert Survived column to factor (Required for confusionMatrix)
train_imputed1$Survived <- as.factor(train_imputed1$Survived)
train_regression$Survived <- as.factor(train_regression$Survived)
train_knn$Survived <- as.factor(train_knn$Survived)

# Get predictions (Convert probabilities to binary predictions: 1 if >0.5 else 0)
pred_mean <- ifelse(predict(logit_mean, type = "response") > 0.5, 1, 0)
pred_reg <- ifelse(predict(logit_reg, type = "response") > 0.5, 1, 0)
pred_knn <- ifelse(predict(logit_knn, type = "response") > 0.5, 1, 0)

# Convert predictions and actual values to factors for confusionMatrix()
pred_mean <- as.factor(pred_mean)
pred_reg <- as.factor(pred_reg)
pred_knn <- as.factor(pred_knn)

# Compute confusion matrices
conf_matrix_mean <- confusionMatrix(pred_mean, train_imputed1$Survived)
conf_matrix_reg <- confusionMatrix(pred_reg, train_regression$Survived)
conf_matrix_knn <- confusionMatrix(pred_knn, train_knn$Survived)

# Print accuracy for each model
cat("Accuracy with Mean/Mode Imputation:", conf_matrix_mean$overall['Accuracy'], "\n")
cat("Accuracy with Regression Imputation:", conf_matrix_reg$overall['Accuracy'], "\n")
cat("Accuracy with KNN Imputation:", conf_matrix_knn$overall['Accuracy'], "\n")

```

- Results show that KNN imputation performed the best in terms of accuracy, followed by regression imputation, and then mean/mode imputation.

#### Model metrics

```{r}
metrics <- function(conf_matrix) {
  data.frame(
    Accuracy = conf_matrix$overall['Accuracy'],
    Sensitivity = conf_matrix$byClass['Sensitivity'],
    Specificity = conf_matrix$byClass['Specificity'],
    F1_Score = conf_matrix$byClass['F1']
  )
}

# Create comparison table
rbind(
  Mean = metrics(conf_matrix_mean),
  Regression = metrics(conf_matrix_reg),
  KNN = metrics(conf_matrix_knn)
)
```


```{r}
library(ggplot2)
library(tidyr)

# Prepare data
results <- data.frame(
  Method = c("Mean/Mode", "Regression", "KNN"),
  Accuracy = c(0.801, 0.808, 0.810),
  F1_Score = c(conf_matrix_mean$byClass['F1'], 
               conf_matrix_reg$byClass['F1'],
               conf_matrix_knn$byClass['F1'])
) %>% pivot_longer(-Method, names_to = "Metric")

# Plot
ggplot(results, aes(Method, value, fill = Metric)) +
  geom_col(position = "dodge") +
  labs(title = "Model Performance Comparison", 
       y = "Score", x = "Imputation Method") +
  scale_fill_brewer(palette = "Set1") +
  theme_minimal()
```

-This bar graph compares the effectiveness of three missing data imputation methods—Mean/Mode, Regression, and KNN—on machine learning model performance. The Y-axis represents the performance scores (ranging from 0.0 to 0.8), while the X-axis lists the imputation methods. Each method is evaluated using two key metrics:

-Accuracy: Measures overall prediction correctness.

-F1-Score: Balances precision and recall (critical for imbalanced datasets).

KNN Imputation Achieves the Best Performance:

- Highest accuracy (0.810) and F1-score (0.850), indicating it best preserves data patterns when filling missing values.

Regression Slightly Trails KNN:

- Close second in accuracy (0.808) and F1-score (0.848), leveraging statistical relationships for reliable imputation.

Mean/Mode Lags Behind:

- Lowest scores (accuracy: 0.801; F1-score: 0.842), as simple averages fail to capture nuanced data structures.



```{r}
library(dplyr)  
library(broom)  
library(ggplot2)

# Get coefficients from each model
coef_mean <- tidy(logit_mean) %>% mutate(Method = "Mean/Mode")
coef_reg <- tidy(logit_reg) %>% mutate(Method = "Regression") 
coef_knn <- tidy(logit_knn) %>% mutate(Method = "KNN")

# Combine all coefficients
coefs <- rbind(coef_mean, coef_reg, coef_knn)

# Plot (simple version)
ggplot(coefs %>% filter(term != "(Intercept)"), 
       aes(x = term, y = estimate, color = Method)) +
  geom_point(size = 3) +
  coord_flip() +
  labs(title = "Columns Importance Across Models",
       x = "columns",
       y = "Coefficient Value") +
  theme_minimal()
```

Y-axis : Lists the features (variables) like SibSp, Sexmale, Pclass, etc.

X-axis : Shows the coefficient values or importance scores of each feature.

 This plot compares how different features influence our model’s predictions and whether their importance changes based on how we handle missing data. For example:

- Sexmale is strongly negative across all methods, confirming that being male significantly lowered survival odds.

- Negative values (left side): The feature has a negative relationship with the target (e.g., higher Pclass = lower survival) i.e Pclass (ticket class) also has a negative effect—higher classes (1st = rich, 3rd = poor) had worse survival rates.


- Positive values (right side): The feature has a positive relationship (e.g., higher Fare = higher survival).Fare shows a positive relationship, suggesting wealthier passengers had better survival chances.

- Features like Embarked (port of boarding) matter less, as their bars are short.

- The importance of Age varies slightly depending on how we fill missing values, but it’s not a dominant factor.


### Conclusion

-   To handle missing values, we applied three different imputation techniques—Mean/Mode Imputation, Regression Imputation, and KNN Imputation. After imputing the missing values, we trained a logistic regression model to predict survival and compared the accuracy of each imputation method.

- Mean/Mode Imputation resulted in an accuracy of 80.13%, as it fills missing values with the column’s mean (for numeric data) or the most frequent category (for categorical data). While simple and efficient, it may not capture complex relationships within the data.

- Regression Imputation improved accuracy to 80.81%, as it predicts missing values based on other variables using linear or multinomial regression. This method provides better estimations than simple mean/mode imputation.

- KNN Imputation achieved the highest accuracy at 81.03%, as it fills missing values based on the nearest neighbors' values, preserving data patterns more effectively.

Overall, KNN imputation performed the best, followed by regression, and then mean/mode. This suggests that more sophisticated imputation techniques can lead to better predictive performance.



-   Discuss the implications of your results.

## References
